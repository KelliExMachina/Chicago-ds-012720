{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "As data scientists, we want to build a model to predict the sale price of a house in Seattle in 2019, based on its square footage. We know that the King County Department of Assessments has comprehensive data available on real property sales in the Seattle area. We need to prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Goals:\n",
    "\n",
    "- practice cleaning a real dataset\n",
    "- practice using `py` files and the terminal in conjunction with jupyter notebooks\n",
    "- run a `py` script through the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kennedy/Documents/GitHub/Chicago-ds-012720/module_1/week_1/day5_more_pandas/pandas_data_cleaning\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, get the data!\n",
    "\n",
    "When working on a project involving data that can fit on our computer, we store it in a `data` directory.\n",
    "\n",
    "```bash\n",
    "cd <project_directory>  # example: cd ~/flatiron_ds/pandas-3\n",
    "mkdir data\n",
    "cd data\n",
    "```\n",
    "\n",
    "Note that `<project_directory>` in angle brackets is a _placeholder_. You should type the path to the actual location on your computer where you're working on this project. Do not literally type `<project_directory>` and _do not type the angle brackets_. You can see an example in the _comment_ to the right of the command above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![terminal](https://media3.giphy.com/media/yR4xZagT71AAM/giphy.gif?cid=790b76115d3620444553533759086a54&rid=giphy.gif)\n",
    "\n",
    "Now, we'll need to download the two data files that we need. We can do this at the command line:\n",
    "\n",
    "```bash\n",
    "wget https://aqua.kingcounty.gov/extranet/assessor/Real%20Property%20Sales.zip\n",
    "wget https://aqua.kingcounty.gov/extranet/assessor/Residential%20Building.zip\n",
    "```\n",
    "\n",
    "*Note:* If you do not have the `wget` command yet, you can install it with `brew install wget`, or use `curl <url> -o <filename>`.\n",
    "\n",
    "Note that `%20` in a URL translates into a space. Even though you will *never put spaces in filenames*, you may need to deal with spaces that _other_ people have used in filenames.\n",
    "\n",
    "There are two ways to handle the spaces in these filenames when referencing them at the command line.\n",
    "\n",
    "\n",
    "![internetgif](https://media2.giphy.com/media/QWkuGmMgphvmE/giphy.gif?cid=790b76115d361f42304a6850369f37ea&rid=giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. You can _escape_ the spaces by putting a backslash (`\\`, remember _backslash is next to backspace_) before each one:\n",
    "\n",
    "`unzip Real\\ Property\\ Sales.zip`\n",
    "\n",
    "This is what happens if you tab-complete the filename in the terminal. Tab completion is your friend!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. You can put the entire filename in quotes:\n",
    "\n",
    "`unzip \"Real Property Sales.zip\"`\n",
    "\n",
    "Try unzipping these files with the `unzip` command. The `unzip` command takes one argument, the name of the file that you want to unzip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building         EXTR_RPSale.csv  EXTR_ResBldg.csv RealSales\n"
     ]
    }
   ],
   "source": [
    "!ls ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv('data/EXTR_RPSale.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeing pink? Warnings are useful!\n",
    "\n",
    "Note the warning above: `DtypeWarning: Columns (1, 2) have mixed types.` Because we start with an index of zero, the columns that we're being warned about are actually the _second_ and _third_ columns, `sales_df['Major']` and `sales_df['Minor']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExciseTaxNbr           int64\n",
       "Major                 object\n",
       "Minor                 object\n",
       "DocumentDate          object\n",
       "SalePrice              int64\n",
       "RecordingNbr          object\n",
       "Volume                object\n",
       "Page                  object\n",
       "PlatNbr               object\n",
       "PlatType              object\n",
       "PlatLot               object\n",
       "PlatBlock             object\n",
       "SellerName            object\n",
       "BuyerName             object\n",
       "PropertyType           int64\n",
       "PrincipalUse           int64\n",
       "SaleInstrument         int64\n",
       "AFForestLand          object\n",
       "AFCurrentUseLand      object\n",
       "AFNonProfitUse        object\n",
       "AFHistoricProperty    object\n",
       "SaleReason             int64\n",
       "PropertyClass          int64\n",
       "SaleWarning           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExciseTaxNbr</th>\n",
       "      <th>Major</th>\n",
       "      <th>Minor</th>\n",
       "      <th>DocumentDate</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>RecordingNbr</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Page</th>\n",
       "      <th>PlatNbr</th>\n",
       "      <th>PlatType</th>\n",
       "      <th>...</th>\n",
       "      <th>PropertyType</th>\n",
       "      <th>PrincipalUse</th>\n",
       "      <th>SaleInstrument</th>\n",
       "      <th>AFForestLand</th>\n",
       "      <th>AFCurrentUseLand</th>\n",
       "      <th>AFNonProfitUse</th>\n",
       "      <th>AFHistoricProperty</th>\n",
       "      <th>SaleReason</th>\n",
       "      <th>PropertyClass</th>\n",
       "      <th>SaleWarning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1600768</td>\n",
       "      <td>330405</td>\n",
       "      <td>100</td>\n",
       "      <td>03/19/1998</td>\n",
       "      <td>215000</td>\n",
       "      <td>199803251689</td>\n",
       "      <td>145</td>\n",
       "      <td>039</td>\n",
       "      <td>330405</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2413752</td>\n",
       "      <td>868146</td>\n",
       "      <td>30</td>\n",
       "      <td>09/11/2009</td>\n",
       "      <td>0</td>\n",
       "      <td>20091022001461</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>18 31 38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1939480</td>\n",
       "      <td>258190</td>\n",
       "      <td>265</td>\n",
       "      <td>02/06/2003</td>\n",
       "      <td>0</td>\n",
       "      <td>20030214003390</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>31 51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2999169</td>\n",
       "      <td>919715</td>\n",
       "      <td>200</td>\n",
       "      <td>07/08/2019</td>\n",
       "      <td>192000</td>\n",
       "      <td>20190712001080</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2220242</td>\n",
       "      <td>334330</td>\n",
       "      <td>1343</td>\n",
       "      <td>05/30/2006</td>\n",
       "      <td>0</td>\n",
       "      <td>20060706002163</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>11 31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ExciseTaxNbr   Major Minor DocumentDate  SalePrice    RecordingNbr Volume  \\\n",
       "0       1600768  330405   100   03/19/1998     215000  199803251689      145   \n",
       "1       2413752  868146    30   09/11/2009          0  20091022001461          \n",
       "2       1939480  258190   265   02/06/2003          0  20030214003390          \n",
       "3       2999169  919715   200   07/08/2019     192000  20190712001080          \n",
       "4       2220242  334330  1343   05/30/2006          0  20060706002163          \n",
       "\n",
       "  Page PlatNbr PlatType  ... PropertyType PrincipalUse SaleInstrument  \\\n",
       "0  039  330405        C  ...            2            2              3   \n",
       "1                        ...            3            2             15   \n",
       "2                        ...            3            6             15   \n",
       "3                        ...            3            2              3   \n",
       "4                        ...            1            6              3   \n",
       "\n",
       "  AFForestLand  AFCurrentUseLand  AFNonProfitUse  AFHistoricProperty  \\\n",
       "0            N                 N               N                   N   \n",
       "1            N                 N               N                   N   \n",
       "2            N                 N               N                   N   \n",
       "3            N                 N               N                   N   \n",
       "4            N                 N               N                   N   \n",
       "\n",
       "  SaleReason PropertyClass SaleWarning  \n",
       "0          1             3              \n",
       "1         11             3    18 31 38  \n",
       "2         10             8       31 51  \n",
       "3          1             3              \n",
       "4         18             7       11 31  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overload?\n",
    "\n",
    "That's a lot of columns. We're only interested in identifying the date, sale price, and square footage of each specific property. What can we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv('data/EXTR_RPSale.csv', low_memory=False, usecols=['DocumentDate','SalePrice','Volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocumentDate</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/19/1998</td>\n",
       "      <td>215000</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09/11/2009</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02/06/2003</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07/08/2019</td>\n",
       "      <td>192000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05/30/2006</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066900</th>\n",
       "      <td>05/11/2004</td>\n",
       "      <td>357450</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066901</th>\n",
       "      <td>12/26/2007</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066902</th>\n",
       "      <td>05/07/2015</td>\n",
       "      <td>680000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066903</th>\n",
       "      <td>11/09/1998</td>\n",
       "      <td>129950</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066904</th>\n",
       "      <td>01/06/2004</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2066905 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DocumentDate  SalePrice Volume\n",
       "0         03/19/1998     215000    145\n",
       "1         09/11/2009          0       \n",
       "2         02/06/2003          0       \n",
       "3         07/08/2019     192000       \n",
       "4         05/30/2006          0       \n",
       "...              ...        ...    ...\n",
       "2066900   05/11/2004     357450       \n",
       "2066901   12/26/2007          0       \n",
       "2066902   05/07/2015     680000       \n",
       "2066903   11/09/1998     129950    142\n",
       "2066904   01/06/2004          0       \n",
       "\n",
       "[2066905 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bldg_df = pd.read_csv('data/EXTR_ResBldg.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another warning! Which column has index 11?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ZipCode'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bldg_df.columns[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['98056', '98056', '98115', ..., '98177', '98053', '98045'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bldg_df.ZipCode.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ZipCode` seems like a potentially useful column. We'll need it to determine which house sales took place in Seattle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So many features!\n",
    "\n",
    "As data scientists, we should be _very_ cautious about discarding potentially useful data. But, today, we're interested in _only_ the total square footage of each property. What can we do?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error!\n",
    "\n",
    "Why are we seeing an error when we try to join the dataframes?\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><pre>\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 2013160 entries, 0 to 2013159\n",
    "Data columns (total 4 columns):\n",
    "Major           object\n",
    "Minor           object\n",
    "DocumentDate    object\n",
    "SalePrice       int64\n",
    "dtypes: int64(1), object(3)\n",
    "memory usage: 61.4+ MB</pre></td>\n",
    "        <td style=\"text-align:left\"><pre>\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 511359 entries, 0 to 511358\n",
    "Data columns (total 4 columns):\n",
    "Major            511359 non-null int64\n",
    "Minor            511359 non-null int64\n",
    "SqFtTotLiving    511359 non-null int64\n",
    "ZipCode          468345 non-null object\n",
    "dtypes: int64(3), object(1)\n",
    "memory usage: 15.6+ MB\n",
    "</pre></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Review the error message in light of the above:\n",
    "\n",
    "* `ValueError: You are trying to merge on object and int64 columns.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error!\n",
    "\n",
    "Note the useful error message above:\n",
    "\n",
    "`ValueError: Unable to parse string \"      \" at position 936643`\n",
    "\n",
    "In this case, we want to treat non-numeric values as missing values. Let's see if there's a way to change how the `pd.to_numeric` function handles errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The single question mark means \"show me the docstring\"\n",
    "pd.to_numeric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the part that we're looking for:\n",
    "```\n",
    "errors : {'ignore', 'raise', 'coerce'}, default 'raise'\n",
    "    - If 'raise', then invalid parsing will raise an exception\n",
    "    - If 'coerce', then invalid parsing will be set as NaN\n",
    "    - If 'ignore', then invalid parsing will return the input\n",
    "```\n",
    "\n",
    "Let's try setting the `errors` parameter to `'coerce'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df['Major'] = pd.to_numeric(sales_df['Major'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! Let's do the same thing with the `Minor` parcel number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df['Minor'] = pd.to_numeric(sales_df['Minor'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try our join again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = pd.merge(sales_df, bldg_df, on=['Major', 'Minor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see right away that we're missing zip codes for many of the sales transactions. (1321536 non-null entries for ZipCode is fewer than the 1436772 entries in the dataframe.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.loc[sales_data['ZipCode'].isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are interested in finding houses in Seattle zip codes, we will need to drop the rows with missing zip codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1334823 homes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn: Data Cleaning with Pandas\n",
    "![turtletype](https://media3.giphy.com/media/cFdHXXm5GhJsc/giphy.gif?cid=790b76115d3627d8354c7179366b0672&rid=giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 311 Service Requests received by the City of Chicago\n",
    "https://data.cityofchicago.org/Service-Requests/311-Service-Requests/v6vf-nfxy\n",
    "\n",
    "\n",
    "\n",
    "###  Read and Investigate data\n",
    "Use multiple notebook cells to accomplish this! Press `[esc]` then `B` to create a new cell below the current cell. Press `[return]` to start typing in the new cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('311_Service_Requests.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create new df with the following columns:\n",
    "    'SR_NUMBER', 'SR_TYPE', 'SR_SHORT_CODE', 'OWNER_DEPARTMENT', 'STATUS',\n",
    "       'CREATED_DATE', 'LAST_MODIFIED_DATE', 'LOCATION','CITY', 'LATITUDE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate and handle missing values\n",
    "\n",
    "What's the right thing to do with missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find out top 3 service types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair Programming:\n",
    "    \n",
    "For these exercises, we will be practicing pair programming. \n",
    "While we work through these exercises, choose who will code and who will supervise.\n",
    "I.E., one person types, and the other suggests the appropriate direction to head in.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-class Exercise: \n",
    "Think about 2 questions each person and use city_df to answer your questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After class : \n",
    "### Turning code into a script\n",
    "\n",
    "#### make a new .py file\n",
    "- open a new `.py` file _or_ open a new jupyter notbook and export as a `.py` file so we can start to edit the `.py` file directly\n",
    "- save the file as `mean_ppsf_seattle.py`\n",
    "- look at all your code between `sales_df = pd.read_csv('data/Real Property Sales.zip')` and question `number 6` above\n",
    "\n",
    "#### review & organize your code\n",
    "- _organize_ your code in the `mean_ppsf_seattle.py` to start with `sales_df = pd.read_csv('data/Real Property Sales.zip')` and end with printing out the mean price per square foot for a house sold in seattle in 2019\n",
    "- the code should be able to run without throwing any errors\n",
    "- remember to include `import pandas as pd` and any other necessary statements at the start of your script\n",
    "\n",
    "#### test your script\n",
    "- go to the terminal\n",
    "- make sure you are in the same directory path as your jupyter notebook and the `.py` file\n",
    "- in the terminal type and then run `python mean_ppsf_seattle.py`\n",
    "- confirm the script returns in terminal what you wanted it to return\n",
    "\n",
    "\n",
    "![anykey](https://media2.giphy.com/media/26BGIqWh2R1fi6JDa/giphy.gif?cid=790b76115d3627d8354c7179366b0672&rid=giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
